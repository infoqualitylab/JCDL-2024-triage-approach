{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# for running on google colab\n",
    "# !pip install keras\n",
    "# !pip install tensorflow"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0DIWCpFnHLz",
    "outputId": "3ddce6b7-704f-43ca-eaf1-a65f906ce7c1",
    "ExecuteTime": {
     "end_time": "2024-10-08T15:06:52.105994Z",
     "start_time": "2024-10-08T15:06:52.103644Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T15:06:52.112990Z",
     "start_time": "2024-10-08T15:06:52.110386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# adapted from https://github.com/Conferences2023/TPDL/blob/main/Citation%20Analysis/LSTM.py\n",
    "'''code of Usman, M., & Balke, W.-T. (2023). On retraction cascade? Citation intention analysis as a quality control mechanism in digital libraries. In O. Alonso, H. Cousijn, G. Silvello, M. Marrero, C. Teixeira Lopes, & S. Marchesin (Eds.), Linking Theory and Practice of Digital Libraries (pp. 117–131). Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-43849-3_11'''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code of Usman, M., & Balke, W.-T. (2023). On retraction cascade? Citation intention analysis as a quality control mechanism in digital libraries. In O. Alonso, H. Cousijn, G. Silvello, M. Marrero, C. Teixeira Lopes, & S. Marchesin (Eds.), Linking Theory and Practice of Digital Libraries (pp. 117–131). Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-43849-3_11'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EX8QmJ-DcOtS",
    "ExecuteTime": {
     "end_time": "2024-10-08T15:06:59.313144Z",
     "start_time": "2024-10-08T15:06:52.181450Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data from CSV file\n",
    "train_data = pd.read_csv('ML_input_data/train_set.csv')\n",
    "test_data = pd.read_csv('ML_input_data/test_set.csv')"
   ],
   "metadata": {
    "id": "Bs8H3itgekRk",
    "ExecuteTime": {
     "end_time": "2024-10-08T15:07:12.579036Z",
     "start_time": "2024-10-08T15:07:12.573098Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_data['Citation context level annotation'])\n",
    "test_labels = le.transform(test_data['Citation context level annotation'])\n",
    "\n",
    "# Tokenize citation context text\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data['Citation context (sent)'])\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['Citation context (sent)'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['Citation context (sent)'])\n",
    "\n",
    "# Pad sequences to same length\n",
    "max_len = 100\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_len)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_len)\n",
    "\n",
    "# Define neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128, input_length=max_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "# model.fit(train_sequences, train_labels, epochs=30, batch_size=32, validation_data=(test_sequences, test_labels))\n",
    "model.fit(train_sequences, train_labels, epochs=30, batch_size=32)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(test_sequences)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_labels, y_pred, target_names=['N', 'Y']))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(test_labels, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0nvfoXZfWZe",
    "outputId": "4ce7cdfc-7a2a-429c-ec3d-b79e27b1d540",
    "ExecuteTime": {
     "end_time": "2024-10-08T15:07:24.681118Z",
     "start_time": "2024-10-08T15:07:13.963770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - accuracy: 0.5448 - loss: 0.6897\n",
      "Epoch 2/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.6747 - loss: 0.6489\n",
      "Epoch 3/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.6275 - loss: 0.6240\n",
      "Epoch 4/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.6823 - loss: 0.5549\n",
      "Epoch 5/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.8188 - loss: 0.4052\n",
      "Epoch 6/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.9367 - loss: 0.3109\n",
      "Epoch 7/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.9645 - loss: 0.1813\n",
      "Epoch 8/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.9786 - loss: 0.1080\n",
      "Epoch 9/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.9740 - loss: 0.0914\n",
      "Epoch 10/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.9853 - loss: 0.0681\n",
      "Epoch 11/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.9860 - loss: 0.0435\n",
      "Epoch 12/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.9959 - loss: 0.0264\n",
      "Epoch 13/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.9926 - loss: 0.0288\n",
      "Epoch 14/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.9853 - loss: 0.0428\n",
      "Epoch 15/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.9897 - loss: 0.0348\n",
      "Epoch 16/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.9973 - loss: 0.0114\n",
      "Epoch 17/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.9909 - loss: 0.0258\n",
      "Epoch 18/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.9836 - loss: 0.0252\n",
      "Epoch 19/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.9943 - loss: 0.0167\n",
      "Epoch 20/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.9976 - loss: 0.0171\n",
      "Epoch 21/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.9901 - loss: 0.0342\n",
      "Epoch 22/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 23/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 24/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 1.0000 - loss: 0.0065\n",
      "Epoch 25/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 26/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 27/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 28/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 29/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.9986 - loss: 0.0049\n",
      "Epoch 30/30\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.76      0.76      0.76        38\n",
      "           Y       0.59      0.59      0.59        22\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.68      0.68      0.68        60\n",
      "weighted avg       0.70      0.70      0.70        60\n",
      "\n",
      "[[29  9]\n",
      " [ 9 13]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# create predictions for all instances\n",
    "full_data = pd.read_csv('ML_input_data/data_all.csv')\n",
    "full_sequences = tokenizer.texts_to_sequences(full_data['Citation context (sent)'])\n",
    "full_sequences = pad_sequences(full_sequences, maxlen=max_len)\n",
    "full_predictions = model.predict(full_sequences)\n",
    "full_predictions = (full_predictions > 0.5)\n",
    "full_data['Predicted label'] = full_predictions\n",
    "# copy this to the input_data if you wanted to verify the entire workflow\n",
    "# however, since the output of LSTM is non-deterministic, you might get slightly different results than reported in the paper\n",
    "full_data.to_csv('ML_output_data/LSTM_prediction_203.csv', index=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66HyYUtKjDFp",
    "outputId": "ad881b8b-8e10-4791-8196-df7329d365c6",
    "ExecuteTime": {
     "end_time": "2024-10-08T15:09:47.326188Z",
     "start_time": "2024-10-08T15:09:47.150533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
